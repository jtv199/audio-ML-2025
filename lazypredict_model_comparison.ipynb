{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LazyPredict Model Comparison for Audio Classification\n",
    "\n",
    "This notebook uses LazyPredict to quickly train and compare multiple machine learning models on the tabular audio features.\n",
    "\n",
    "LazyPredict automatically trains 40+ sklearn models and provides a comparison table showing their performance.\n",
    "\n",
    "## Workflow:\n",
    "1. Load tabular features and labels\n",
    "2. Filter to single-class samples\n",
    "3. Split into train/test sets\n",
    "4. Run LazyClassifier to train all models\n",
    "5. Compare results and identify best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install lazypredict if not already installed\n",
    "# !pip install lazypredict -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# LazyPredict imports\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading features...\n",
      "Features shape: (4970, 2475)\n",
      "\n",
      "Loading labels...\n",
      "Labels shape: (4970, 2)\n",
      "\n",
      "Merged dataframe shape: (4970, 2477)\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "DATA_PATH = Path('./work')\n",
    "FEATURES_CSV = DATA_PATH / 'trn_curated_feature.csv'\n",
    "LABELS_CSV = Path('./input/train_curated.csv')\n",
    "\n",
    "# Load features\n",
    "print(\"Loading features...\")\n",
    "features_df = pd.read_csv(FEATURES_CSV)\n",
    "print(f\"Features shape: {features_df.shape}\")\n",
    "\n",
    "# Load labels\n",
    "print(\"\\nLoading labels...\")\n",
    "labels_df = pd.read_csv(LABELS_CSV)\n",
    "print(f\"Labels shape: {labels_df.shape}\")\n",
    "\n",
    "# Merge features and labels\n",
    "df = features_df.merge(labels_df, left_on='file', right_on='fname', how='inner')\n",
    "print(f\"\\nMerged dataframe shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Filter to Single-Class Samples\n",
    "\n",
    "LazyPredict works with single-label classification, so we filter to samples with only one label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original samples: 4970\n",
      "Single-class samples: 4269\n",
      "Percentage single-class: 85.90%\n",
      "\n",
      "Number of unique classes: 74\n",
      "\n",
      "Top 10 classes:\n",
      "labels\n",
      "Finger_snapping           75\n",
      "Scissors                  75\n",
      "Zipper_(clothing)         75\n",
      "Gong                      75\n",
      "Printer                   75\n",
      "Marimba_and_xylophone     75\n",
      "Keys_jangling             75\n",
      "Skateboard                75\n",
      "Computer_keyboard         75\n",
      "Burping_and_eructation    74\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count number of labels per sample\n",
    "df['num_labels'] = df['labels'].str.count(',') + 1\n",
    "\n",
    "# Filter to single-class only\n",
    "single_class_df = df[df['num_labels'] == 1].copy()\n",
    "print(f\"Original samples: {len(df)}\")\n",
    "print(f\"Single-class samples: {len(single_class_df)}\")\n",
    "print(f\"Percentage single-class: {100 * len(single_class_df) / len(df):.2f}%\")\n",
    "\n",
    "# Check class distribution\n",
    "print(f\"\\nNumber of unique classes: {single_class_df['labels'].nunique()}\")\n",
    "print(f\"\\nTop 10 classes:\")\n",
    "print(single_class_df['labels'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Data for Training\n",
    "\n",
    "We'll use a 80/20 train/test split for LazyPredict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of feature columns: 2474\n",
      "X shape: (4269, 2474)\n",
      "y shape: (4269,)\n"
     ]
    }
   ],
   "source": [
    "# Prepare feature columns and target\n",
    "feature_cols = [col for col in single_class_df.columns \n",
    "                if col not in ['file', 'fname', 'labels', 'num_labels']]\n",
    "\n",
    "print(f\"Number of feature columns: {len(feature_cols)}\")\n",
    "\n",
    "X = single_class_df[feature_cols]\n",
    "y = single_class_df['labels']\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in X: 2474\n",
      "Missing values in y: 0\n",
      "\n",
      "Removing rows with missing values...\n",
      "After removal - X shape: (4268, 2474), y shape: (4268,)\n"
     ]
    }
   ],
   "source": [
    "# Check for and remove missing values\n",
    "print(f\"Missing values in X: {X.isnull().sum().sum()}\")\n",
    "print(f\"Missing values in y: {y.isnull().sum()}\")\n",
    "\n",
    "if X.isnull().any().any():\n",
    "    print(\"\\nRemoving rows with missing values...\")\n",
    "    mask = ~X.isnull().any(axis=1)\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "    print(f\"After removal - X shape: {X.shape}, y shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 3414 samples (80.0%)\n",
      "Test set: 854 samples (20.0%)\n",
      "\n",
      "Number of classes: 74\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test sets (80/20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples ({100*len(X_train)/len(X):.1f}%)\")\n",
    "print(f\"Test set: {len(X_test)} samples ({100*len(X_test)/len(X):.1f}%)\")\n",
    "print(f\"\\nNumber of classes: {y.nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run LazyPredict in Segments\n",
    "\n",
    "This will train models in 4 groups to identify problematic models and avoid getting stuck.\n",
    "\n",
    "**Strategy:** Train specific model groups separately with timeout protection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model segments defined:\n",
      "\n",
      "Segment 1: Fast Models (5 models):\n",
      "  - DummyClassifier\n",
      "  - BernoulliNB\n",
      "  - GaussianNB\n",
      "  - NearestCentroid\n",
      "  - Perceptron\n",
      "\n",
      "Segment 2: Linear Models (7 models):\n",
      "  - LogisticRegression\n",
      "  - RidgeClassifier\n",
      "  - RidgeClassifierCV\n",
      "  - PassiveAggressiveClassifier\n",
      "  - SGDClassifier\n",
      "  - LinearDiscriminantAnalysis\n",
      "  - LinearSVC\n",
      "\n",
      "Segment 3: Tree & Neighbor Models (5 models):\n",
      "  - DecisionTreeClassifier\n",
      "  - ExtraTreeClassifier\n",
      "  - KNeighborsClassifier\n",
      "  - RandomForestClassifier\n",
      "  - ExtraTreesClassifier\n",
      "\n",
      "Segment 4: Ensemble Models (4 models):\n",
      "  - AdaBoostClassifier\n",
      "  - BaggingClassifier\n",
      "  - GradientBoostingClassifier\n",
      "  - CalibratedClassifierCV\n",
      "\n",
      "============================================================\n",
      "TOTAL: 21 models across 4 segments\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Define model groups (split into 4 segments)\n",
    "# These are common sklearn classifiers that LazyPredict uses\n",
    "\n",
    "from sklearn.ensemble import (AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier,\n",
    "                               RandomForestClassifier, GradientBoostingClassifier)\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB, MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\n",
    "from sklearn.linear_model import (LogisticRegression, RidgeClassifier, RidgeClassifierCV,\n",
    "                                   PassiveAggressiveClassifier, Perceptron, SGDClassifier)\n",
    "from sklearn.svm import LinearSVC, SVC, NuSVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.semi_supervised import LabelPropagation, LabelSpreading\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Segment 1: Fast Naive Bayes and simple models (should be quick)\n",
    "segment_1 = [\n",
    "    ('DummyClassifier', DummyClassifier(strategy='most_frequent', random_state=42)),\n",
    "    ('BernoulliNB', BernoulliNB()),\n",
    "    ('GaussianNB', GaussianNB()),\n",
    "    ('NearestCentroid', NearestCentroid()),\n",
    "    ('Perceptron', Perceptron(random_state=42, max_iter=1000)),\n",
    "]\n",
    "\n",
    "# Segment 2: Linear models (moderate speed)\n",
    "segment_2 = [\n",
    "    ('LogisticRegression', LogisticRegression(random_state=42, max_iter=1000, n_jobs=-1)),\n",
    "    ('RidgeClassifier', RidgeClassifier(random_state=42)),\n",
    "    ('RidgeClassifierCV', RidgeClassifierCV()),\n",
    "    ('PassiveAggressiveClassifier', PassiveAggressiveClassifier(random_state=42, max_iter=1000)),\n",
    "    ('SGDClassifier', SGDClassifier(random_state=42, max_iter=1000)),\n",
    "    ('LinearDiscriminantAnalysis', LinearDiscriminantAnalysis()),\n",
    "    ('LinearSVC', LinearSVC(random_state=42, max_iter=1000, dual=False)),\n",
    "]\n",
    "\n",
    "# Segment 3: Tree-based and neighbor models (can be slow)\n",
    "segment_3 = [\n",
    "    ('DecisionTreeClassifier', DecisionTreeClassifier(random_state=42)),\n",
    "    ('ExtraTreeClassifier', ExtraTreeClassifier(random_state=42)),\n",
    "    ('KNeighborsClassifier', KNeighborsClassifier(n_neighbors=5, n_jobs=-1)),\n",
    "    ('RandomForestClassifier', RandomForestClassifier(random_state=42, n_estimators=100, n_jobs=-1)),\n",
    "    ('ExtraTreesClassifier', ExtraTreesClassifier(random_state=42, n_estimators=100, n_jobs=-1)),\n",
    "]\n",
    "\n",
    "# Segment 4: Ensemble and complex models (slowest - skip problematic ones)\n",
    "segment_4 = [\n",
    "    ('AdaBoostClassifier', AdaBoostClassifier(random_state=42, algorithm='SAMME')),\n",
    "    ('BaggingClassifier', BaggingClassifier(random_state=42, n_jobs=-1)),\n",
    "    ('GradientBoostingClassifier', GradientBoostingClassifier(random_state=42)),\n",
    "    ('CalibratedClassifierCV', CalibratedClassifierCV(n_jobs=-1)),\n",
    "]\n",
    "\n",
    "# Store all segments\n",
    "segments = [\n",
    "    (\"Segment 1: Fast Models\", segment_1),\n",
    "    (\"Segment 2: Linear Models\", segment_2),\n",
    "    (\"Segment 3: Tree & Neighbor Models\", segment_3),\n",
    "    (\"Segment 4: Ensemble Models\", segment_4),\n",
    "]\n",
    "\n",
    "print(\"Model segments defined:\")\n",
    "total_models = 0\n",
    "for i, (name, models_list) in enumerate(segments, 1):\n",
    "    print(f\"\\n{name} ({len(models_list)} models):\")\n",
    "    for model_name, _ in models_list:\n",
    "        print(f\"  - {model_name}\")\n",
    "    total_models += len(models_list)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"TOTAL: {total_models} models across 4 segments\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to train models with timeout protection\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score\n",
    "import signal\n",
    "\n",
    "class TimeoutError(Exception):\n",
    "    pass\n",
    "\n",
    "def timeout_handler(signum, frame):\n",
    "    raise TimeoutError()\n",
    "\n",
    "def train_and_evaluate_model(name, model, X_train, X_test, y_train, y_test, timeout=300):\n",
    "    \"\"\"\n",
    "    Train and evaluate a single model with timeout protection.\n",
    "    \n",
    "    Args:\n",
    "        timeout: Maximum time in seconds (default 300 = 5 minutes)\n",
    "    \"\"\"\n",
    "    print(f\"  Training {name}...\", end=\" \", flush=True)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Set timeout alarm (only works on Unix-like systems)\n",
    "        signal.signal(signal.SIGALRM, timeout_handler)\n",
    "        signal.alarm(timeout)\n",
    "        \n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Cancel alarm\n",
    "        signal.alarm(0)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"✓ Done in {elapsed_time:.2f}s (Acc: {accuracy:.4f})\")\n",
    "        \n",
    "        return {\n",
    "            'Model': name,\n",
    "            'Accuracy': accuracy,\n",
    "            'Balanced Accuracy': balanced_acc,\n",
    "            'F1 Score': f1,\n",
    "            'Time Taken': elapsed_time,\n",
    "            'Status': 'Success'\n",
    "        }\n",
    "        \n",
    "    except TimeoutError:\n",
    "        signal.alarm(0)\n",
    "        print(f\"✗ TIMEOUT after {timeout}s\")\n",
    "        return {\n",
    "            'Model': name,\n",
    "            'Accuracy': None,\n",
    "            'Balanced Accuracy': None,\n",
    "            'F1 Score': None,\n",
    "            'Time Taken': timeout,\n",
    "            'Status': 'Timeout'\n",
    "        }\n",
    "    except Exception as e:\n",
    "        signal.alarm(0)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(f\"✗ ERROR: {str(e)[:50]}\")\n",
    "        return {\n",
    "            'Model': name,\n",
    "            'Accuracy': None,\n",
    "            'Balanced Accuracy': None,\n",
    "            'F1 Score': None,\n",
    "            'Time Taken': elapsed_time,\n",
    "            'Status': f'Error: {str(e)[:50]}'\n",
    "        }\n",
    "\n",
    "print(\"Training function defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SEGMENT 1: Fast Models (Naive Bayes, Simple Classifiers)\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_and_evaluate_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m segment_1_results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name, model \u001b[38;5;129;01min\u001b[39;00m segment_1:\n\u001b[0;32m----> 8\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate_model\u001b[49m(model_name, model, X_train, X_test, y_train, y_test, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m180\u001b[39m)\n\u001b[1;32m      9\u001b[0m     segment_1_results\u001b[38;5;241m.\u001b[39mappend(result)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Convert to DataFrame\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_and_evaluate_model' is not defined"
     ]
    }
   ],
   "source": [
    "# RUN SEGMENT 1: Fast Models\n",
    "print(\"=\" * 80)\n",
    "print(\"SEGMENT 1: Fast Models (Naive Bayes, Simple Classifiers)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "segment_1_results = []\n",
    "for model_name, model in segment_1:\n",
    "    result = train_and_evaluate_model(model_name, model, X_train, X_test, y_train, y_test, timeout=180)\n",
    "    segment_1_results.append(result)\n",
    "\n",
    "# Convert to DataFrame\n",
    "segment_1_df = pd.DataFrame(segment_1_results).set_index('Model')\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SEGMENT 1 RESULTS:\")\n",
    "print(\"=\" * 80)\n",
    "print(segment_1_df[['Accuracy', 'Balanced Accuracy', 'F1 Score', 'Time Taken', 'Status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN SEGMENT 2: Linear Models\n",
    "print(\"=\" * 80)\n",
    "print(\"SEGMENT 2: Linear Models\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "segment_2_results = []\n",
    "for model_name, model in segment_2:\n",
    "    result = train_and_evaluate_model(model_name, model, X_train, X_test, y_train, y_test, timeout=300)\n",
    "    segment_2_results.append(result)\n",
    "\n",
    "# Convert to DataFrame\n",
    "segment_2_df = pd.DataFrame(segment_2_results).set_index('Model')\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SEGMENT 2 RESULTS:\")\n",
    "print(\"=\" * 80)\n",
    "print(segment_2_df[['Accuracy', 'Balanced Accuracy', 'F1 Score', 'Time Taken', 'Status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN SEGMENT 3: Tree-based Models\n",
    "print(\"=\" * 80)\n",
    "print(\"SEGMENT 3: Tree-based Models\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "segment_3_results = []\n",
    "for model_name, model in segment_3:\n",
    "    result = train_and_evaluate_model(model_name, model, X_train, X_test, y_train, y_test, timeout=600)\n",
    "    segment_3_results.append(result)\n",
    "\n",
    "# Convert to DataFrame\n",
    "segment_3_df = pd.DataFrame(segment_3_results).set_index('Model')\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SEGMENT 3 RESULTS:\")\n",
    "print(\"=\" * 80)\n",
    "print(segment_3_df[['Accuracy', 'Balanced Accuracy', 'F1 Score', 'Time Taken', 'Status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN SEGMENT 4: Ensemble Models\n",
    "print(\"=\" * 80)\n",
    "print(\"SEGMENT 4: Ensemble Models (Slowest - may take 10+ minutes)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "segment_4_results = []\n",
    "for model_name, model in segment_4:\n",
    "    result = train_and_evaluate_model(model_name, model, X_train, X_test, y_train, y_test, timeout=900)\n",
    "    segment_4_results.append(result)\n",
    "\n",
    "# Convert to DataFrame\n",
    "segment_4_df = pd.DataFrame(segment_4_results).set_index('Model')\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SEGMENT 4 RESULTS:\")\n",
    "print(\"=\" * 80)\n",
    "print(segment_4_df[['Accuracy', 'Balanced Accuracy', 'F1 Score', 'Time Taken', 'Status']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Combine All Results\n",
    "\n",
    "Merge all segment results into a single DataFrame for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all results\n",
    "all_results = segment_1_results + segment_2_results + segment_3_results + segment_4_results\n",
    "models = pd.DataFrame(all_results).set_index('Model')\n",
    "\n",
    "# Display full results\n",
    "print(\"=\" * 80)\n",
    "print(\"COMBINED MODEL COMPARISON RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "print(models)\n",
    "\n",
    "# Filter to successful models only\n",
    "successful_models = models[models['Status'] == 'Success'].copy()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"SUMMARY: {len(successful_models)}/{len(models)} models completed successfully\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Show failed/timeout models if any\n",
    "failed_models = models[models['Status'] != 'Success']\n",
    "if len(failed_models) > 0:\n",
    "    print(\"\\nFailed/Timeout Models:\")\n",
    "    print(failed_models[['Time Taken', 'Status']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display top 10 models by accuracy (successful models only)\n",
    "if len(successful_models) > 0:\n",
    "    print(\"\\nTop 10 Models by Accuracy:\")\n",
    "    print(\"=\" * 80)\n",
    "    top_10 = successful_models.sort_values('Accuracy', ascending=False).head(10)\n",
    "    print(top_10[['Accuracy', 'Balanced Accuracy', 'F1 Score', 'Time Taken']])\n",
    "else:\n",
    "    print(\"No successful models to display\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of metrics for top 10 models\n",
    "top_10_models = models.sort_values('Accuracy', ascending=False).head(10)\n",
    "metrics_to_plot = ['Accuracy', 'Balanced Accuracy', 'F1 Score']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(top_10_models[metrics_to_plot], annot=True, fmt='.3f', \n",
    "            cmap='RdYlGn', vmin=0, vmax=1, ax=ax)\n",
    "ax.set_title('Performance Metrics Heatmap - Top 10 Models')\n",
    "ax.set_xlabel('Metric')\n",
    "ax.set_ylabel('Model')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of accuracies across all models\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.hist(models['Accuracy'], bins=20, edgecolor='black', alpha=0.7)\n",
    "ax.axvline(models['Accuracy'].mean(), color='red', linestyle='--', \n",
    "          label=f'Mean: {models[\"Accuracy\"].mean():.3f}')\n",
    "ax.axvline(models['Accuracy'].median(), color='green', linestyle='--', \n",
    "          label=f'Median: {models[\"Accuracy\"].median():.3f}')\n",
    "ax.set_xlabel('Accuracy')\n",
    "ax.set_ylabel('Number of Models')\n",
    "ax.set_title('Distribution of Model Accuracies')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Recommendations\n",
    "\n",
    "Based on the results, let's identify the best models for different use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model Recommendations:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Best overall accuracy\n",
    "best_acc_model = models['Accuracy'].idxmax()\n",
    "print(f\"\\n1. BEST OVERALL ACCURACY:\")\n",
    "print(f\"   Model: {best_acc_model}\")\n",
    "print(f\"   Accuracy: {models.loc[best_acc_model, 'Accuracy']:.4f}\")\n",
    "print(f\"   F1 Score: {models.loc[best_acc_model, 'F1 Score']:.4f}\")\n",
    "print(f\"   Training Time: {models.loc[best_acc_model, 'Time Taken']:.2f}s\")\n",
    "\n",
    "# Best balanced accuracy (good for imbalanced classes)\n",
    "best_bal_model = models['Balanced Accuracy'].idxmax()\n",
    "print(f\"\\n2. BEST BALANCED ACCURACY (for imbalanced classes):\")\n",
    "print(f\"   Model: {best_bal_model}\")\n",
    "print(f\"   Balanced Accuracy: {models.loc[best_bal_model, 'Balanced Accuracy']:.4f}\")\n",
    "print(f\"   Regular Accuracy: {models.loc[best_bal_model, 'Accuracy']:.4f}\")\n",
    "print(f\"   Training Time: {models.loc[best_bal_model, 'Time Taken']:.2f}s\")\n",
    "\n",
    "# Fastest model with good accuracy (>50% of best accuracy)\n",
    "threshold = models['Accuracy'].max() * 0.85\n",
    "fast_models = models[models['Accuracy'] >= threshold].sort_values('Time Taken')\n",
    "if len(fast_models) > 0:\n",
    "    fastest_good = fast_models.index[0]\n",
    "    print(f\"\\n3. FASTEST MODEL (with ≥85% of best accuracy):\")\n",
    "    print(f\"   Model: {fastest_good}\")\n",
    "    print(f\"   Accuracy: {models.loc[fastest_good, 'Accuracy']:.4f}\")\n",
    "    print(f\"   Training Time: {models.loc[fastest_good, 'Time Taken']:.2f}s\")\n",
    "\n",
    "# Best F1 Score\n",
    "best_f1_model = models['F1 Score'].idxmax()\n",
    "print(f\"\\n4. BEST F1 SCORE (balance of precision & recall):\")\n",
    "print(f\"   Model: {best_f1_model}\")\n",
    "print(f\"   F1 Score: {models.loc[best_f1_model, 'F1 Score']:.4f}\")\n",
    "print(f\"   Accuracy: {models.loc[best_f1_model, 'Accuracy']:.4f}\")\n",
    "print(f\"   Training Time: {models.loc[best_f1_model, 'Time Taken']:.2f}s\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to CSV\n",
    "output_file = 'lazypredict_results.csv'\n",
    "models.to_csv(output_file)\n",
    "print(f\"Results saved to: {output_file}\")\n",
    "\n",
    "# Save top 10 models\n",
    "top_10_file = 'lazypredict_top10.csv'\n",
    "models.sort_values('Accuracy', ascending=False).head(10).to_csv(top_10_file)\n",
    "print(f\"Top 10 models saved to: {top_10_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "LazyPredict has trained and evaluated 40+ machine learning models on the audio classification task.\n",
    "\n",
    "### Key Takeaways:\n",
    "- Identified the best performing models without manual hyperparameter tuning\n",
    "- Compared accuracy, F1 score, and training time across all models\n",
    "- Found models suitable for different use cases (accuracy vs speed)\n",
    "\n",
    "### Next Steps:\n",
    "1. Take the top-performing models and fine-tune their hyperparameters\n",
    "2. Try ensemble methods combining multiple top models\n",
    "3. Investigate why certain models perform better on this audio dataset\n",
    "4. Consider feature engineering to improve performance further"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "freesound",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
