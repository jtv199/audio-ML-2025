# Training Metrics Summary
Extracted from Jupyter notebooks

## cnn-2d-basic-solution-powered-by-fast-ai.ipynb
- **Model**: resnet18
- **Pretrained**: No
- **Total Epochs**: 115
- **Training Phases**: 5

### Training Phases:

**Phase 1** (15 epochs, lr=1e-1)

| Epoch | Train Loss | Valid Loss | LWLRAP | Time |
|-------|------------|------------|--------|------|
| 0 | 0.257204 | 0.092621 | 0.080807 | 00:07 |
| 1 | 0.125856 | 0.098057 | 0.113652 | 00:06 |
| 2 | 0.092281 | 0.088215 | 0.167518 | 00:07 |
| 3 | 0.077910 | 0.073455 | 0.237748 | 00:06 |
| 4 | 0.069874 | 0.067782 | 0.290014 | 00:06 |
| 0 | 0.065608 | 0.064218 | 0.301837 | 00:06 |
| 1 | 0.065135 | 0.064631 | 0.288753 | 00:08 |
| 2 | 0.064070 | 0.064463 | 0.314039 | 00:08 |
| 3 | 0.063191 | 0.059353 | 0.343956 | 00:11 |
| 4 | 0.060965 | 0.062565 | 0.313999 | 00:09 |
| ... | ... | ... | ... | ... |
| 9 | 0.053170 | 0.052388 | 0.467086 | 00:07 |

**Phase 2** (20 epochs, lr=3e-3)

| Epoch | Train Loss | Valid Loss | LWLRAP | Time |
|-------|------------|------------|--------|------|
| 0 | 0.051991 | 0.051631 | 0.470720 | 00:07 |
| 1 | 0.052161 | 0.053330 | 0.443764 | 00:07 |
| 2 | 0.052060 | 0.051735 | 0.464560 | 00:07 |
| 3 | 0.052109 | 0.052666 | 0.466942 | 00:07 |
| 4 | 0.051975 | 0.049786 | 0.490339 | 00:07 |
| 5 | 0.051208 | 0.049408 | 0.481335 | 00:07 |
| 6 | 0.050216 | 0.050489 | 0.485607 | 00:07 |
| 7 | 0.049348 | 0.051459 | 0.510845 | 00:07 |
| 8 | 0.048190 | 0.052376 | 0.494911 | 00:07 |
| 9 | 0.047023 | 0.051461 | 0.503337 | 00:07 |
| ... | ... | ... | ... | ... |
| 19 | 0.040037 | 0.042186 | 0.600605 | 00:07 |

**Phase 3** (20 epochs, lr=1e-3)

| Epoch | Train Loss | Valid Loss | LWLRAP | Time |
|-------|------------|------------|--------|------|
| 0 | 0.040064 | 0.041995 | 0.608249 | 00:07 |
| 1 | 0.040419 | 0.045252 | 0.588846 | 00:06 |
| 2 | 0.040690 | 0.043076 | 0.599714 | 00:07 |
| 3 | 0.040872 | 0.045541 | 0.597180 | 00:08 |
| 4 | 0.039834 | 0.044372 | 0.589830 | 00:07 |
| 5 | 0.039737 | 0.042361 | 0.588977 | 00:08 |
| 6 | 0.039252 | 0.046235 | 0.586345 | 00:08 |
| 7 | 0.038953 | 0.042371 | 0.604621 | 00:07 |
| 8 | 0.038739 | 0.041712 | 0.602699 | 00:08 |
| 9 | 0.037773 | 0.040401 | 0.623241 | 00:07 |
| ... | ... | ... | ... | ... |
| 19 | 0.034320 | 0.038959 | 0.636252 | 00:06 |

**Phase 4** (50 epochs, lr=slice(1e-3, 3e-3)

| Epoch | Train Loss | Valid Loss | LWLRAP | Time |
|-------|------------|------------|--------|------|
| 0 | 0.034173 | 0.038106 | 0.646734 | 00:06 |
| 1 | 0.033807 | 0.038358 | 0.644416 | 00:06 |
| 2 | 0.033950 | 0.038826 | 0.639638 | 00:06 |
| 3 | 0.033963 | 0.038318 | 0.640181 | 00:06 |
| 4 | 0.034095 | 0.038343 | 0.650936 | 00:06 |
| 5 | 0.034570 | 0.038738 | 0.650174 | 00:07 |
| 6 | 0.034619 | 0.038718 | 0.642490 | 00:06 |
| 7 | 0.034814 | 0.038449 | 0.641735 | 00:06 |
| 8 | 0.034733 | 0.038557 | 0.638884 | 00:06 |
| 9 | 0.034653 | 0.039165 | 0.646030 | 00:06 |
| ... | ... | ... | ... | ... |
| 49 | 0.016093 | 0.034764 | 0.716798 | 00:06 |

**Phase 5** (10 epochs, lr=slice(1e-4, 1e-3)

| Epoch | Train Loss | Valid Loss | LWLRAP | Time |
|-------|------------|------------|--------|------|
| 0 | 0.015374 | 0.034062 | 0.721457 | 00:06 |
| 1 | 0.015763 | 0.035769 | 0.708780 | 00:06 |
| 2 | 0.016273 | 0.035495 | 0.717269 | 00:06 |
| 3 | 0.016240 | 0.035703 | 0.718489 | 00:06 |
| 4 | 0.015892 | 0.034279 | 0.722885 | 00:06 |
| 5 | 0.015751 | 0.035728 | 0.715368 | 00:06 |
| 6 | 0.015790 | 0.034893 | 0.713184 | 00:06 |
| 7 | 0.015052 | 0.034998 | 0.721080 | 00:07 |
| 8 | 0.014952 | 0.034665 | 0.711812 | 00:06 |
| 9 | 0.014597 | 0.034925 | 0.711425 | 00:06 |

### Final Metrics (Epoch 9):
- Train Loss: 0.014597
- Valid Loss: 0.034925
- LWLRAP: 0.711425

## mobilnet-test.ipynb
- **Model**: mobilenetv4_conv_small
- **Pretrained**: No
- **Total Epochs**: 90
- **Training Phases**: 5

### Training Phases:

**Phase 1** (10 epochs, lr=1e-1)

| Epoch | Train Loss | Valid Loss | Accuracy Multi | LWLRAP | Time |
|-------|------------|------------|----------------|--------|------|
| 0 | 0.066219 | 0.063769 | 0.985501 | 0.254828 | 00:09 |
| 1 | 0.065657 | 0.065295 | 0.985488 | 0.227073 | 00:09 |
| 2 | 0.065673 | 0.062370 | 0.985526 | 0.289337 | 00:09 |
| 3 | 0.064748 | 0.061863 | 0.985488 | 0.294606 | 00:10 |
| 4 | 0.062526 | 0.060243 | 0.985538 | 0.303682 | 00:10 |
| 5 | 0.061206 | 0.060578 | 0.985224 | 0.334532 | 00:11 |
| 6 | 0.059045 | 0.066225 | 0.984859 | 0.312681 | 00:09 |
| 7 | 0.056967 | 4.320676 | 0.985312 | 0.421219 | 00:09 |
| 8 | 0.055243 | 110.806099 | 0.985249 | 0.426409 | 00:09 |
| 9 | 0.054196 | 2.490208 | 0.984960 | 0.432401 | 00:09 |

**Phase 2** (5 epochs, lr=3e-3)

| Epoch | Train Loss | Valid Loss | Accuracy Multi | LWLRAP | Time |
|-------|------------|------------|----------------|--------|------|
| 0 | 0.053159 | 70.693611 | 0.985412 | 0.430902 | 00:09 |
| 1 | 0.053441 | 6.753978 | 0.985714 | 0.437083 | 00:09 |
| 2 | 0.053271 | 39.483402 | 0.985626 | 0.452036 | 00:11 |
| 3 | 0.053227 | 0.053526 | 0.985790 | 0.440157 | 00:11 |
| 4 | 0.053015 | 0.051171 | 0.986154 | 0.458650 | 00:11 |

**Phase 3** (20 epochs, lr=1e-3)

| Epoch | Train Loss | Valid Loss | Accuracy Multi | LWLRAP | Time |
|-------|------------|------------|----------------|--------|------|
| 0 | 0.036816 | 0.041868 | 0.988167 | 0.590655 | 00:09 |
| 1 | 0.036873 | 0.042081 | 0.988254 | 0.590050 | 00:10 |
| 2 | 0.037130 | 0.042973 | 0.987915 | 0.587602 | 00:13 |
| 3 | 0.037793 | 0.043951 | 0.987500 | 0.564983 | 00:13 |
| 4 | 0.037730 | 0.042823 | 0.987978 | 0.592670 | 00:09 |
| 5 | 0.037262 | 0.044774 | 0.987714 | 0.562195 | 00:10 |
| 6 | 0.036915 | 0.044740 | 0.987538 | 0.570216 | 00:09 |
| 7 | 0.035936 | 0.042318 | 0.987877 | 0.595427 | 00:09 |
| 8 | 0.035671 | 0.042474 | 0.987902 | 0.590921 | 00:09 |
| 9 | 0.034527 | 0.042352 | 0.988292 | 0.603545 | 00:12 |
| ... | ... | ... | ... | ... | ... |
| 19 | 0.030050 | 0.040351 | 0.988607 | 0.627044 | 00:11 |

**Phase 4** (50 epochs, lr=slice(1e-3, 3e-3)

| Epoch | Train Loss | Valid Loss | Accuracy Multi | LWLRAP | Time |
|-------|------------|------------|----------------|--------|------|
| 0 | 0.030500 | 0.040263 | 0.988745 | 0.631121 | 00:09 |
| 1 | 0.030434 | 0.040963 | 0.988695 | 0.620020 | 00:10 |
| 2 | 0.030270 | 0.040468 | 0.988758 | 0.626308 | 00:13 |
| 3 | 0.030085 | 0.040879 | 0.988783 | 0.630167 | 00:16 |
| 4 | 0.030333 | 0.040899 | 0.988607 | 0.611014 | 00:15 |
| 5 | 0.030208 | 0.042092 | 0.988431 | 0.615310 | 00:10 |
| 6 | 0.030433 | 0.042276 | 0.988255 | 0.604517 | 00:10 |
| 7 | 0.030663 | 0.042463 | 0.988531 | 0.611201 | 00:10 |
| 8 | 0.031106 | 0.042690 | 0.988368 | 0.611106 | 00:11 |
| 9 | 0.030819 | 0.042507 | 0.988493 | 0.608690 | 00:10 |
| ... | ... | ... | ... | ... | ... |
| 49 | 0.015392 | 0.043195 | 0.989374 | 0.648340 | 00:13 |

**Phase 5** (5 epochs, lr=slice(1e-4, 1e-3)

| Epoch | Train Loss | Valid Loss | Accuracy Multi | LWLRAP | Time |
|-------|------------|------------|----------------|--------|------|
| 0 | 0.015961 | 0.042997 | 0.989273 | 0.648228 | 00:09 |
| 1 | 0.015742 | 0.043337 | 0.989147 | 0.647679 | 00:11 |
| 2 | 0.015644 | 0.044660 | 0.989223 | 0.644295 | 00:12 |
| 3 | 0.015855 | 0.043077 | 0.989437 | 0.654780 | 00:11 |
| 4 | 0.015886 | 0.043148 | 0.989311 | 0.650506 | 00:09 |

### Final Metrics (Epoch 4):
- Train Loss: 0.015886
- Valid Loss: 0.043148
- Accuracy Multi: 0.989311
- LWLRAP: 0.650506

## vision-transformer-transfer.ipynb
- **Model**: deit_tiny_patch16_224
- **Pretrained**: Yes
- **Total Epochs**: 106
- **Training Phases**: 5

### Training Phases:

**Phase 1** (15 epochs, lr=1e-1)

| Epoch | Train Loss | Valid Loss | Accuracy Multi | LWLRAP | Time |
|-------|------------|------------|----------------|--------|------|
| 0 | 0.258748 | 0.254969 | 0.985475 | 0.068106 | 00:16 |
| 1 | 0.124267 | 0.087776 | 0.985475 | 0.074581 | 00:14 |
| 2 | 0.091168 | 0.088614 | 0.985450 | 0.075990 | 00:17 |
| 3 | 0.081637 | 0.075428 | 0.985438 | 0.106057 | 00:15 |
| 4 | 0.077418 | 0.074468 | 0.985475 | 0.101675 | 00:14 |
| 0 | 0.075024 | 0.074136 | 0.985463 | 0.111928 | 00:14 |
| 1 | 0.075011 | 0.109400 | 0.984633 | 0.114396 | 00:14 |
| 2 | 0.075198 | 0.074581 | 0.985450 | 0.107594 | 00:17 |
| 3 | 0.075296 | 0.073942 | 0.985475 | 0.105916 | 00:15 |
| 4 | 0.074905 | 0.073581 | 0.985475 | 0.133890 | 00:14 |
| ... | ... | ... | ... | ... | ... |
| 9 | 0.073398 | 0.073074 | 0.985475 | 0.123952 | 00:16 |

**Phase 2** (20 epochs, lr=3e-3)

| Epoch | Train Loss | Valid Loss | Accuracy Multi | LWLRAP | Time |
|-------|------------|------------|----------------|--------|------|
| 0 | 0.073617 | 0.073131 | 0.985475 | 0.129232 | 00:14 |
| 1 | 0.073560 | 0.073032 | 0.985475 | 0.130925 | 00:14 |
| 2 | 0.073447 | 0.073277 | 0.985475 | 0.122154 | 00:14 |
| 3 | 0.074345 | 0.074033 | 0.985475 | 0.106875 | 00:14 |
| 4 | 0.073950 | 0.073412 | 0.985312 | 0.131841 | 00:14 |
| 5 | 0.073430 | 0.072536 | 0.985450 | 0.150075 | 00:14 |
| 6 | 0.072866 | 0.072208 | 0.985463 | 0.140481 | 00:13 |
| 7 | 0.072500 | 0.072057 | 0.985450 | 0.147872 | 00:14 |
| 8 | 0.072076 | 0.071892 | 0.985400 | 0.141701 | 00:13 |
| 9 | 0.072007 | 0.071128 | 0.985438 | 0.166212 | 00:13 |
| ... | ... | ... | ... | ... | ... |
| 19 | 0.070763 | 0.070865 | 0.985450 | 0.169178 | 00:13 |

**Phase 3** (20 epochs, lr=1e-3)

| Epoch | Train Loss | Valid Loss | Accuracy Multi | LWLRAP | Time |
|-------|------------|------------|----------------|--------|------|
| 0 | 0.070103 | 0.070568 | 0.985438 | 0.167135 | 00:14 |
| 1 | 0.070659 | 0.070227 | 0.985463 | 0.176275 | 00:13 |
| 2 | 0.070347 | 0.070205 | 0.985400 | 0.169812 | 00:13 |
| 3 | 0.070210 | 0.070561 | 0.985337 | 0.167580 | 00:13 |
| 4 | 0.070396 | 0.070063 | 0.985425 | 0.175834 | 00:14 |
| 5 | 0.070764 | 0.070852 | 0.985312 | 0.171246 | 00:14 |
| 6 | 0.070908 | 0.070179 | 0.985413 | 0.181533 | 00:14 |
| 7 | 0.070455 | 0.070049 | 0.985463 | 0.191926 | 00:15 |
| 8 | 0.070497 | 0.070000 | 0.985475 | 0.178113 | 00:18 |
| 9 | 0.070674 | 0.069895 | 0.985450 | 0.191502 | 00:15 |
| ... | ... | ... | ... | ... | ... |
| 19 | 0.069594 | 0.069829 | 0.985475 | 0.179885 | 00:15 |

**Phase 4** (50 epochs, lr=slice(1e-3, 3e-3)

| Epoch | Train Loss | Valid Loss | Accuracy Multi | LWLRAP | Time |
|-------|------------|------------|----------------|--------|------|
| 0 | 0.069585 | 0.069466 | 0.985475 | 0.185948 | 00:13 |
| 1 | 0.069623 | 0.069502 | 0.985450 | 0.180228 | 00:13 |
| 2 | 0.069732 | 0.069884 | 0.985475 | 0.184691 | 00:13 |
| 3 | 0.069595 | 0.069374 | 0.985350 | 0.183559 | 00:14 |
| 4 | 0.069354 | 0.069440 | 0.985475 | 0.189072 | 00:14 |
| 5 | 0.069594 | 0.069065 | 0.985475 | 0.194303 | 00:15 |
| 6 | 0.069829 | 0.069222 | 0.985450 | 0.189199 | 00:13 |
| 7 | 0.069841 | 0.068921 | 0.985463 | 0.198893 | 00:14 |
| 8 | 0.069649 | 0.069349 | 0.985450 | 0.185045 | 00:14 |
| 9 | 0.069728 | 0.069363 | 0.985475 | 0.178501 | 00:14 |
| ... | ... | ... | ... | ... | ... |
| 49 | 0.066836 | 0.132784 | 0.984834 | 0.234214 | 00:13 |

**Phase 5** (1 epochs, lr=slice(1e-4, 1e-3)

| Epoch | Train Loss | Valid Loss | Accuracy Multi | LWLRAP | Time |
|-------|------------|------------|----------------|--------|------|
| 0 | 0.066462 | 0.066228 | 0.985463 | 0.235876 | 00:13 |

### Final Metrics (Epoch 0):
- Train Loss: 0.066462
- Valid Loss: 0.066228
- Accuracy Multi: 0.985463
- LWLRAP: 0.235876

## vision-transformer-no-transfer.ipynb
- **Model**: deit_tiny_patch16_224
- **Pretrained**: No
- **Total Epochs**: 115
- **Training Phases**: 5

### Training Phases:

**Phase 1** (15 epochs, lr=1e-1)

| Epoch | Train Loss | Valid Loss | Accuracy Multi | LWLRAP | Time |
|-------|------------|------------|----------------|--------|------|
| 0 | 0.357745 | 7.901134 | 0.278182 | 0.070984 | 00:14 |
| 1 | 0.186497 | 0.084119 | 0.985475 | 0.072470 | 00:14 |
| 2 | 0.109832 | 0.076806 | 0.985475 | 0.092763 | 00:15 |
| 3 | 0.085767 | 0.074588 | 0.985475 | 0.105219 | 00:14 |
| 4 | 0.078163 | 0.073336 | 0.985475 | 0.135070 | 00:14 |
| 0 | 0.074662 | 0.073479 | 0.985475 | 0.125070 | 00:14 |
| 1 | 0.074524 | 0.073640 | 0.985475 | 0.125820 | 00:14 |
| 2 | 0.074627 | 0.073467 | 0.985475 | 0.118975 | 00:15 |
| 3 | 0.074545 | 0.073014 | 0.985475 | 0.131396 | 00:15 |
| 4 | 0.074100 | 0.072806 | 0.985475 | 0.132528 | 00:14 |
| ... | ... | ... | ... | ... | ... |
| 9 | 0.072048 | 0.071612 | 0.985475 | 0.157176 | 00:18 |

**Phase 2** (20 epochs, lr=3e-3)

| Epoch | Train Loss | Valid Loss | Accuracy Multi | LWLRAP | Time |
|-------|------------|------------|----------------|--------|------|
| 0 | 0.072117 | 0.071493 | 0.985475 | 0.165348 | 00:19 |
| 1 | 0.072261 | 0.071403 | 0.985475 | 0.162292 | 00:14 |
| 2 | 0.072208 | 0.071271 | 0.985475 | 0.161023 | 00:17 |
| 3 | 0.072184 | 0.071016 | 0.985450 | 0.163968 | 00:15 |
| 4 | 0.072224 | 0.070853 | 0.985475 | 0.162749 | 00:15 |
| 5 | 0.071734 | 0.070422 | 0.985475 | 0.172723 | 00:17 |
| 6 | 0.071708 | 0.070346 | 0.985475 | 0.178544 | 00:19 |
| 7 | 0.071143 | 0.070082 | 0.985475 | 0.177948 | 00:14 |
| 8 | 0.071130 | 0.069964 | 0.985475 | 0.173377 | 00:14 |
| 9 | 0.070928 | 0.070103 | 0.985475 | 0.176864 | 00:15 |
| ... | ... | ... | ... | ... | ... |
| 19 | 0.069409 | 0.068539 | 0.985475 | 0.196553 | 00:13 |

**Phase 3** (20 epochs, lr=1e-3)

| Epoch | Train Loss | Valid Loss | Accuracy Multi | LWLRAP | Time |
|-------|------------|------------|----------------|--------|------|
| 0 | 0.069482 | 0.068410 | 0.985475 | 0.199514 | 00:17 |
| 1 | 0.069430 | 0.068483 | 0.985475 | 0.191004 | 00:17 |
| 2 | 0.069331 | 0.068811 | 0.985475 | 0.195691 | 00:16 |
| 3 | 0.069441 | 0.068853 | 0.985475 | 0.193071 | 00:15 |
| 4 | 0.069166 | 0.068680 | 0.985475 | 0.191160 | 00:17 |
| 5 | 0.069222 | 0.068707 | 0.985475 | 0.183980 | 00:15 |
| 6 | 0.069329 | 0.068169 | 0.985475 | 0.199504 | 00:15 |
| 7 | 0.068894 | 0.067827 | 0.985475 | 0.204278 | 00:15 |
| 8 | 0.069167 | 0.068199 | 0.985475 | 0.197519 | 00:15 |
| 9 | 0.068932 | 0.068127 | 0.985475 | 0.209780 | 00:15 |
| ... | ... | ... | ... | ... | ... |
| 19 | 0.068469 | 0.067851 | 0.985475 | 0.213892 | 00:17 |

**Phase 4** (50 epochs, lr=slice(1e-3, 3e-3)

| Epoch | Train Loss | Valid Loss | Accuracy Multi | LWLRAP | Time |
|-------|------------|------------|----------------|--------|------|
| 0 | 0.068555 | 0.067949 | 0.985475 | 0.196394 | 00:17 |
| 1 | 0.068725 | 0.067426 | 0.985475 | 0.208210 | 00:17 |
| 2 | 0.068606 | 0.067744 | 0.985475 | 0.208037 | 00:16 |
| 3 | 0.068870 | 0.067769 | 0.985475 | 0.204594 | 00:19 |
| 4 | 0.068817 | 0.067653 | 0.985475 | 0.205328 | 00:21 |
| 5 | 0.068589 | 0.068244 | 0.985475 | 0.203208 | 00:18 |
| 6 | 0.068628 | 0.067830 | 0.985475 | 0.205749 | 00:17 |
| 7 | 0.068875 | 0.067871 | 0.985475 | 0.201317 | 00:15 |
| 8 | 0.068350 | 0.067744 | 0.985488 | 0.199930 | 00:15 |
| 9 | 0.068701 | 0.067646 | 0.985475 | 0.210102 | 00:15 |
| ... | ... | ... | ... | ... | ... |
| 49 | 0.065586 | 0.064973 | 0.985475 | 0.253575 | 00:14 |

**Phase 5** (10 epochs, lr=slice(1e-4, 1e-3)

| Epoch | Train Loss | Valid Loss | Accuracy Multi | LWLRAP | Time |
|-------|------------|------------|----------------|--------|------|
| 0 | 0.065562 | 0.065161 | 0.985475 | 0.243495 | 00:15 |
| 1 | 0.065755 | 0.065230 | 0.985475 | 0.249506 | 00:15 |
| 2 | 0.065819 | 0.065064 | 0.985463 | 0.243320 | 00:15 |
| 3 | 0.065696 | 0.065205 | 0.985475 | 0.242994 | 00:13 |
| 4 | 0.065667 | 0.064770 | 0.985463 | 0.244644 | 00:13 |
| 5 | 0.065625 | 0.065168 | 0.985463 | 0.241704 | 00:14 |
| 6 | 0.065573 | 0.064695 | 0.985475 | 0.252377 | 00:13 |
| 7 | 0.065697 | 0.065620 | 0.985475 | 0.232346 | 00:13 |
| 8 | 0.065459 | 0.065028 | 0.985475 | 0.243717 | 00:13 |
| 9 | 0.065553 | 0.064540 | 0.985475 | 0.253036 | 00:13 |

### Final Metrics (Epoch 9):
- Train Loss: 0.065553
- Valid Loss: 0.064540
- Accuracy Multi: 0.985475
- LWLRAP: 0.253036

## vision-transformer-cvit-smaller.ipynb
- **Model**: convit_tiny
- **Pretrained**: No
- **Total Epochs**: 102
- **Training Phases**: 5

### Training Phases:

**Phase 1** (10 epochs, lr=1e-1)

| Epoch | Train Loss | Valid Loss | Accuracy Multi | LWLRAP | Time |
|-------|------------|------------|----------------|--------|------|
| 0 | 0.073457 | 0.072117 | 0.985475 | 0.145525 | 00:20 |
| 1 | 0.073426 | 0.074862 | 0.985274 | 0.102254 | 00:21 |
| 2 | 0.073283 | 0.077467 | 0.985350 | 0.094039 | 00:19 |
| 3 | 0.073379 | 0.073281 | 0.985350 | 0.132877 | 00:19 |
| 4 | 0.073181 | 0.076538 | 0.985475 | 0.103449 | 00:18 |
| 5 | 0.072467 | 0.072997 | 0.985375 | 0.121832 | 00:19 |
| 6 | 0.071381 | 0.074093 | 0.985199 | 0.123982 | 00:19 |
| 7 | 0.070989 | 0.070335 | 0.985425 | 0.163006 | 00:19 |
| 8 | 0.070755 | 0.070870 | 0.985325 | 0.160063 | 00:20 |
| 9 | 0.070421 | 0.070461 | 0.985324 | 0.167218 | 00:19 |

**Phase 2** (20 epochs, lr=3e-3)

| Epoch | Train Loss | Valid Loss | Accuracy Multi | LWLRAP | Time |
|-------|------------|------------|----------------|--------|------|
| 0 | 0.070394 | 0.070738 | 0.985236 | 0.177476 | 00:19 |
| 1 | 0.070586 | 0.070791 | 0.985274 | 0.178850 | 00:19 |
| 2 | 0.070441 | 0.073186 | 0.985136 | 0.123743 | 00:18 |
| 3 | 0.070350 | 0.073611 | 0.985375 | 0.117146 | 00:19 |
| 4 | 0.070324 | 0.073716 | 0.985136 | 0.133193 | 00:19 |
| 5 | 0.070024 | 0.074370 | 0.985299 | 0.114607 | 00:19 |
| 6 | 0.070208 | 0.073504 | 0.985249 | 0.135090 | 00:19 |
| 7 | 0.069496 | 0.084114 | 0.984922 | 0.090742 | 00:20 |
| 8 | 0.069711 | 0.077086 | 0.985350 | 0.109328 | 00:19 |
| 9 | 0.069591 | 0.080256 | 0.985375 | 0.098751 | 00:20 |
| ... | ... | ... | ... | ... | ... |
| 19 | 0.068001 | 0.068209 | 0.985450 | 0.206373 | 00:20 |

**Phase 3** (12 epochs, lr=1e-3)

| Epoch | Train Loss | Valid Loss | Accuracy Multi | LWLRAP | Time |
|-------|------------|------------|----------------|--------|------|
| 0 | 0.067676 | 0.067832 | 0.985413 | 0.209598 | 00:22 |
| 1 | 0.068017 | 0.068173 | 0.985463 | 0.197997 | 00:20 |
| 2 | 0.067954 | 0.068681 | 0.985387 | 0.188781 | 00:20 |
| 3 | 0.068317 | 0.088709 | 0.983979 | 0.092929 | 00:20 |
| 4 | 0.068338 | 0.071175 | 0.985450 | 0.139633 | 00:21 |
| 5 | 0.068010 | 0.068290 | 0.985299 | 0.199758 | 00:19 |
| 6 | 0.068244 | 0.069185 | 0.985463 | 0.183443 | 00:21 |
| 7 | 0.067855 | 0.100222 | 0.983212 | 0.091977 | 00:21 |
| 8 | 0.068037 | 0.067676 | 0.985438 | 0.203384 | 00:19 |
| 9 | 0.067799 | 0.069179 | 0.985450 | 0.168364 | 00:21 |
| ... | ... | ... | ... | ... | ... |
| 11 | 0.067876 | 0.070219 | 0.985450 | 0.164811 | 00:21 |

**Phase 4** (50 epochs, lr=slice(1e-3, 3e-3)

| Epoch | Train Loss | Valid Loss | Accuracy Multi | LWLRAP | Time |
|-------|------------|------------|----------------|--------|------|
| 0 | 0.068555 | 0.067949 | 0.985475 | 0.196394 | 00:17 |
| 1 | 0.068725 | 0.067426 | 0.985475 | 0.208210 | 00:17 |
| 2 | 0.068606 | 0.067744 | 0.985475 | 0.208037 | 00:16 |
| 3 | 0.068870 | 0.067769 | 0.985475 | 0.204594 | 00:19 |
| 4 | 0.068817 | 0.067653 | 0.985475 | 0.205328 | 00:21 |
| 5 | 0.068589 | 0.068244 | 0.985475 | 0.203208 | 00:18 |
| 6 | 0.068628 | 0.067830 | 0.985475 | 0.205749 | 00:17 |
| 7 | 0.068875 | 0.067871 | 0.985475 | 0.201317 | 00:15 |
| 8 | 0.068350 | 0.067744 | 0.985488 | 0.199930 | 00:15 |
| 9 | 0.068701 | 0.067646 | 0.985475 | 0.210102 | 00:15 |
| ... | ... | ... | ... | ... | ... |
| 49 | 0.065586 | 0.064973 | 0.985475 | 0.253575 | 00:14 |

**Phase 5** (10 epochs, lr=slice(1e-4, 1e-3)

| Epoch | Train Loss | Valid Loss | Accuracy Multi | LWLRAP | Time |
|-------|------------|------------|----------------|--------|------|
| 0 | 0.065562 | 0.065161 | 0.985475 | 0.243495 | 00:15 |
| 1 | 0.065755 | 0.065230 | 0.985475 | 0.249506 | 00:15 |
| 2 | 0.065819 | 0.065064 | 0.985463 | 0.243320 | 00:15 |
| 3 | 0.065696 | 0.065205 | 0.985475 | 0.242994 | 00:13 |
| 4 | 0.065667 | 0.064770 | 0.985463 | 0.244644 | 00:13 |
| 5 | 0.065625 | 0.065168 | 0.985463 | 0.241704 | 00:14 |
| 6 | 0.065573 | 0.064695 | 0.985475 | 0.252377 | 00:13 |
| 7 | 0.065697 | 0.065620 | 0.985475 | 0.232346 | 00:13 |
| 8 | 0.065459 | 0.065028 | 0.985475 | 0.243717 | 00:13 |
| 9 | 0.065553 | 0.064540 | 0.985475 | 0.253036 | 00:13 |

### Final Metrics (Epoch 9):
- Train Loss: 0.065553
- Valid Loss: 0.064540
- Accuracy Multi: 0.985475
- LWLRAP: 0.253036
